{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Algorithmique et programmation ISE Eco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Installation de bibliothèque nécessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THEME 1: Les données économique de la Côte d'Ivoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* données issue de l'Université de Sherbrooke, là nous allons mettre en place un code qui va scraper les données économiques sur plusieurs années. pour cela nous definissons une fonction qu prend en paramètre le code du pays. Evidement le site est dynamique;nous avons recours à Selenium pour parcouru "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données de l'URL https://perspective.usherbrooke.ca/bilan/servlet/BMTendanceStatPays?codeTheme=2&codeStat=SP.POP.IDH.IN&codePays=CIV&optionsPeriodes=Aucune ont été enregistrées dans idh.csv avec succès.\n",
      "Les données de l'URL https://perspective.usherbrooke.ca/bilan/servlet/BMTendanceStatPays?codeTheme=2&codeStat=FP.CPI.TOTL&codePays=CIV&optionsPeriodes=Aucune ont été enregistrées dans iphc.csv avec succès.\n",
      "Les données de l'URL https://perspective.usherbrooke.ca/bilan/servlet/BMTendanceStatPays?codeTheme=2&codeStat=PMQUANDL.GINI.V1&codePays=CIV&optionsPeriodes=Aucune ont été enregistrées dans gini.csv avec succès.\n",
      "Les données de l'URL https://perspective.usherbrooke.ca/bilan/servlet/BMTendanceStatPays?codeTheme=2&codeStat=NY.GDP.MKTP.KD&codePays=CIV&optionsPeriodes=Aucune ont été enregistrées dans pib_courant.csv avec succès.\n",
      "Les données de l'URL https://perspective.usherbrooke.ca/bilan/servlet/BMTendanceStatPays?codeTheme=2&codeStat=NY.GDP.PCAP.KD&codePays=CIV&optionsPeriodes=Aucune ont été enregistrées dans pib_hbt.csv avec succès.\n",
      "Les données de l'URL https://perspective.usherbrooke.ca/bilan/servlet/BMTendanceStatPays?codeTheme=2&codeStat=NV.AGR.TOTL.ZS&codePays=CIV&optionsPeriodes=Aucune ont été enregistrées dans va_agri.csv avec succès.\n",
      "Les données de l'URL https://perspective.usherbrooke.ca/bilan/servlet/BMTendanceStatPays?codeTheme=2&codeStat=NV.IND.TOTL.ZS&codePays=CIV&optionsPeriodes=Aucune ont été enregistrées dans va_indus.csv avec succès.\n",
      "Les données de l'URL https://perspective.usherbrooke.ca/bilan/servlet/BMTendanceStatPays?codeTheme=2&codeStat=NV.SRV.TOTL.ZS&codePays=CIV&optionsPeriodes=Aucune ont été enregistrées dans va_serv.csv avec succès.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Liste des indicateurs et leurs codes\n",
    "indicateurs = {\n",
    "    'idh': 'SP.POP.IDH.IN',\n",
    "    'iphc': 'FP.CPI.TOTL',\n",
    "    'gini': 'PMQUANDL.GINI.V1',\n",
    "    'pib_courant': 'NY.GDP.MKTP.KD',\n",
    "    'pib_hbt': 'NY.GDP.PCAP.KD',\n",
    "    'va_agri': 'NV.AGR.TOTL.ZS',\n",
    "    'va_indus': 'NV.IND.TOTL.ZS',\n",
    "    'va_serv': 'NV.SRV.TOTL.ZS',\n",
    "}\n",
    "\n",
    "# Modèle d'URL\n",
    "url_template = (\n",
    "    \"https://perspective.usherbrooke.ca/bilan/servlet/BMTendanceStatPays?\"\n",
    "    \"codeTheme=2&codeStat={stat_code}&codePays={country_code}&optionsPeriodes=Aucune\"\n",
    ")\n",
    "\n",
    "# Fonction pour générer les URLs\n",
    "def generate_urls(indicateurs, country_code):\n",
    "    return {nom: url_template.format(stat_code=code, country_code=country_code) for nom, code in indicateurs.items()}\n",
    "\n",
    "# Fonction principale de scraping\n",
    "def scrap_data(country_code):\n",
    "    urls_with_filenames = generate_urls(indicateurs, country_code)\n",
    "\n",
    "    for nom_fichier, url in urls_with_filenames.items():\n",
    "        driver = None\n",
    "        try:\n",
    "            # Initialiser le navigateur Edge\n",
    "            driver = webdriver.Edge()\n",
    "\n",
    "            # Ouvrir l'URL dans le navigateur\n",
    "            driver.get(url)\n",
    "\n",
    "            # Attendre que la page se charge complètement\n",
    "            wait = WebDriverWait(driver, 20)\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"tbody#listeDonnee td\")))\n",
    "\n",
    "            # Trouver les éléments <td> contenant les années et les valeurs\n",
    "            data_elements = driver.find_elements(By.CSS_SELECTOR, \"tbody#listeDonnee td\")\n",
    "\n",
    "            # Parcourir les éléments et extraire le texte\n",
    "            data = [elem.text for elem in data_elements]\n",
    "\n",
    "            # Extraire les années et les valeurs en utilisant le slicing pour les séparer\n",
    "            annees = data[::3]\n",
    "            croissance_pop = data[1::3]\n",
    "\n",
    "            # Générer le nom complet du fichier en ajoutant l'extension CSV\n",
    "            nom_fichier_csv = f'{nom_fichier}.csv'\n",
    "\n",
    "            # Enregistrer les données dans un fichier CSV\n",
    "            with open(nom_fichier_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow(['Année', nom_fichier])  # Écrire l'en-tête\n",
    "                for annee, taux_croissance_pop in zip(annees, croissance_pop):\n",
    "                    writer.writerow([annee, taux_croissance_pop])\n",
    "\n",
    "            print(f\"Les données de l'URL {url} ont été enregistrées dans {nom_fichier_csv} avec succès.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Une erreur s'est produite en traitant {url}: {e}\")\n",
    "\n",
    "        finally:\n",
    "            # Fermer le navigateur proprement\n",
    "            if driver:\n",
    "                driver.quit()\n",
    "\n",
    "# Exemple d'utilisation pour la Côte d'Ivoire\n",
    "scrap_data(\"CIV\")  # Code ISO du pays Côte d'Ivoire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ANSTAT : l'Agence Nationale de la Statistique de Cote d'Ivoire, nous avons scraper les données demographque, économique et portant sur les conditions de vie. le site etant dynamique, nous avons utilisé Selenium pour parcouru les differentes categores citées haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Données extraites pour demographic : 4 items. Fichier enregistré dans d:\\ISE\\COURS\\ALGO_PRO\\Projet_Algo_DROH_Romaric\\Scripts\\données\\demographic_data.csv\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Erreur pour un item : list index out of range\n",
      "Données extraites pour economic : 5 items. Fichier enregistré dans d:\\ISE\\COURS\\ALGO_PRO\\Projet_Algo_DROH_Romaric\\Scripts\\données\\economic_data.csv\n",
      "Données extraites pour living : 4 items. Fichier enregistré dans d:\\ISE\\COURS\\ALGO_PRO\\Projet_Algo_DROH_Romaric\\Scripts\\données\\living_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "driver.get(\"https://www.anstat.ci\")\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Définir le chemin du dossier \"données\" de manière explicite\n",
    "data_folder = os.path.join(os.getcwd(), 'données')\n",
    "\n",
    "# Créer le dossier \"données\" s'il n'existe pas\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "# Fonction pour scraper les données d'un menu donné\n",
    "def scrape_data(menu_id, group_name):\n",
    "    # Cliquer sur l'onglet correspondant\n",
    "    menu = wait.until(EC.element_to_be_clickable((By.ID, menu_id)))\n",
    "    menu.click()\n",
    "\n",
    "    # Pause pour laisser le contenu se charger (ajuster selon les besoins)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Attendre que les éléments soient visibles\n",
    "    wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"item\")))\n",
    "\n",
    "    # Scraper les données\n",
    "    items = driver.find_elements(By.CLASS_NAME, \"item\")\n",
    "    group_data = []\n",
    "\n",
    "    for item in items:\n",
    "        try:\n",
    "            # Extraire les données\n",
    "            title = item.find_element(By.CLASS_NAME, \"titleIndicateur\").text.strip()\n",
    "            year = item.find_element(By.TAG_NAME, \"small\").text.strip()\n",
    "            value_element = item.find_element(By.CLASS_NAME, \"valIndicateur\")\n",
    "            value = value_element.text.split(\"\\n\")[0].strip()\n",
    "            unit = value_element.find_element(By.TAG_NAME, \"sup\").text.strip()\n",
    "            update_date = item.find_elements(By.TAG_NAME, \"p\")[2].text.split(\": \")[1]\n",
    "            coverage = item.find_elements(By.TAG_NAME, \"p\")[3].text.split(\": \")[1]\n",
    "            description = item.find_element(By.CLASS_NAME, \"ind_descript\").text.strip()\n",
    "            # Ajouter aux données\n",
    "            group_data.append({\n",
    "                \"title\": title,\n",
    "                \"year\": year,\n",
    "                \"value\": value + \" \" + unit,\n",
    "                \"update_date\": update_date,\n",
    "                \"coverage\": coverage,\n",
    "                \"description\": description\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur pour un item : {e}\")\n",
    "\n",
    "    # Sauvegarder les données dans un fichier CSV dans le dossier \"données\"\n",
    "    file_path = os.path.join(data_folder, f'{group_name}_data.csv')\n",
    "    with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"title\", \"year\", \"value\", \"update_date\", \"coverage\", \"description\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(group_data)\n",
    "\n",
    "    print(f\"Données extraites pour {group_name} : {len(group_data)} items. Fichier enregistré dans {file_path}\")\n",
    "\n",
    "# Scraper les données pour chaque menu\n",
    "scrape_data(\"fdv\", \"demographic\")  # Démographie\n",
    "scrape_data(\"midv\", \"economic\")    # Économie\n",
    "scrape_data(\"enddv\", \"living\")     # Conditions de vie\n",
    "\n",
    "# Fermer le navigateur\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THEME 2: EMPLOI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par la suite nous allons scraper les offres d'emploi sur google carrière, nous avons voulu utlser BaeutifoulSoup et requests comme outils de scraping. Pour cela, nous avons énumerer les urls, faire appel à des requêtes pour parcouru les pages. car dans un domane il y'a plusieurs offres reparties sur differentes pages. Une fois nous avons voulu nous passer de Selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping de l'URL : https://www.google.com/about/careers/applications/jobs/results/?hl=fr-CA\n",
      "Les données ont été enregistrées dans offres_emploi_multiple.csv\n",
      "Scraping de l'URL : https://www.google.com/about/careers/applications/jobs/results/?tag=ai-spotlight&hl=en_US\n",
      "Les données ont été enregistrées dans offres_emploi_multiple.csv\n",
      "Scraping de l'URL : https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US\n",
      "Page 2 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 3 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 4 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 5 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 6 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 7 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 8 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 9 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 10 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 11 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 12 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 13 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 14 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 15 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 16 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 17 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 18 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 19 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 20 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 21 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 22 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 23 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 24 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 25 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 26 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Page 27 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US...\n",
      "Les données ont été enregistrées dans offres_emploi_multiple.csv\n",
      "Scraping de l'URL : https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Platforms%20and%20Ecosystems%22&hl=en_US\n",
      "Les données ont été enregistrées dans offres_emploi_multiple.csv\n",
      "Scraping de l'URL : https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US\n",
      "Page 2 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 3 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 4 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 5 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 6 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 7 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 8 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 9 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 10 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 11 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 12 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 13 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 14 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 15 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 16 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 17 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 18 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 19 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 20 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 21 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 22 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 23 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 24 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 25 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 26 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 27 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 28 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 29 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 30 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 31 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Page 32 traitée pour l'URL: https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US...\n",
      "Les données ont été enregistrées dans offres_emploi_multiple.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "urls = [\n",
    "    'https://www.google.com/about/careers/applications/jobs/results/?hl=fr-CA',\n",
    "    'https://www.google.com/about/careers/applications/jobs/results/?tag=ai-spotlight&hl=en_US',\n",
    "    'https://www.google.com/about/careers/applications/jobs/results/?company=Google&company=YouTube&jlo=en_US&q=Hardware%20Engineer&hl=en_US',\n",
    "    'https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Platforms%20and%20Ecosystems%22&hl=en_US',\n",
    "    'https://www.google.com/about/careers/applications/jobs/results/?distance=50&hl=en_US&jlo=en_US&q=%22Site%20reliability%20engineer%22&hl=en_US'\n",
    "]\n",
    "\n",
    "\n",
    "output_file = 'offres_emploi_multiple.csv'\n",
    "\n",
    "# En-têtes pour le CSV\n",
    "headers = ['Domaine', 'Titre du Poste', 'Nom de l\\'Entreprise', 'Lieu', 'Compétences']\n",
    "\n",
    "# Fonction pour scraper et enregistrer les données\n",
    "def scraper_to_csv(url, output_file):\n",
    "    try:\n",
    "        page_number = 1  \n",
    "        while True:\n",
    "      \n",
    "            page_url = f\"{url}&start={(page_number - 1) * 20}\"\n",
    "            \n",
    "        \n",
    "            response = requests.get(page_url)\n",
    "            response.raise_for_status()  \n",
    "    \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            job_titles = soup.find_all('h3', class_='QJPWVe')  \n",
    "            companies = soup.find_all('span', class_='RP7SMd')\n",
    "            locations = soup.find_all('span', class_='pwO9Dc vo5qdf')\n",
    "            skills = soup.find_all('div', class_='Xsxa1e')\n",
    "\n",
    "           \n",
    "            pagination_status = soup.find('div', class_='VfPpkd-wZVHld-gruSEe-j4LONd')\n",
    "            if pagination_status:\n",
    "                rows_text = pagination_status.text.strip()\n",
    "               \n",
    "                match = re.search(r'(\\d+)\\s*(sur|of)\\s*(\\d+)', rows_text)\n",
    "                if match:\n",
    "                    total_rows = int(match.group(3))  \n",
    "                else:\n",
    "                    print(f\"Le format de pagination est inattendu : {rows_text}\")\n",
    "                    total_rows = 0  \n",
    "            with open(output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                if page_number == 1:  \n",
    "                    writer.writerow(headers) \n",
    "\n",
    "                \n",
    "                for title, company, location, skill in zip(job_titles, companies, locations, skills):\n",
    "                   \n",
    "                    title_text = title.text.strip() if title else \"N/A\"\n",
    "\n",
    "                   \n",
    "                    company_name = company.find('span').text.strip() if company.find('span') else \"N/A\"\n",
    "\n",
    "                    \n",
    "                    location_text = \" / \".join([loc.text.strip() for loc in location.find_all('span') if loc.text.strip()]) if location else \"N/A\"\n",
    "\n",
    "              \n",
    "                    skill_list = skill.find_all('li')\n",
    "                    skills_text = \" / \".join([skill_item.text.strip() for skill_item in skill_list]) if skill_list else \"N/A\"\n",
    "\n",
    "                    # Écrire la ligne dans le CSV\n",
    "                    writer.writerow([url, title_text, company_name, location_text, skills_text])\n",
    "\n",
    "            # Si nous avons parcouru toutes les pages, sortir de la boucle\n",
    "            if page_number * 20 >= total_rows:\n",
    "                break\n",
    "\n",
    "            \n",
    "            page_number += 1\n",
    "            print(f\"Page {page_number} traitée pour l'URL: {url}...\")\n",
    "\n",
    "           \n",
    "            time.sleep(2)\n",
    "\n",
    "        print(f\"Les données ont été enregistrées dans {output_file}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la récupération de la page : {e}\")\n",
    "\n",
    "\n",
    "for url in urls:\n",
    "    print(f\"Scraping de l'URL : {url}\")\n",
    "    scraper_to_csv(url, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
